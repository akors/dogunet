{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akors/.conda/envs/ml/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/home/akors/.conda/envs/ml/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets\n",
    "import torch.utils.data\n",
    "import monai.metrics\n",
    "\n",
    "import transforms\n",
    "import datasets\n",
    "\n",
    "from brain_segmentation_pytorch.unet import UNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inf = transforms.make_transforms(datasets.DATASET_STATS[\"2012\"][\"rgb_mean\"], datasets.DATASET_STATS[\"2012\"][\"rgb_std\"])\n",
    "tr_img_inv = transforms.inv_normalize(datasets.DATASET_STATS[\"2012\"][\"rgb_mean\"], datasets.DATASET_STATS[\"2012\"][\"rgb_std\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = torchvision.datasets.wrap_dataset_for_transforms_v2(torchvision.datasets.VOCSegmentation(\n",
    "    root=dataroot,\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,\n",
    "    transforms=tr_inf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = torchvision.datasets.wrap_dataset_for_transforms_v2(torchvision.datasets.VOCSegmentation(\n",
    "    root=dataroot,\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transforms=tr_inf))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointfile = \"../checkpoints/test.chpt.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model from checkpoint file\n",
    "checkpoint = torch.load(checkpointfile)\n",
    "unet_features = checkpoint['model_state_dict']['encoder1.enc1conv1.weight'].size(0)\n",
    "model = UNet(\n",
    "    in_channels=3,\n",
    "    out_channels=datasets.CLASS_MAX+1,\n",
    "    init_features=unet_features,\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topclass_dict(mask: torch.Tensor, k: int=4):\n",
    "    pred_classes, counts = mask.unique(return_counts=True)\n",
    "    topcounts, topcounts_idx = torch.topk(counts, min(k, len(counts)))\n",
    "    #topclasses = pred_classes[topcounts_idx]\n",
    "\n",
    "    top_k_classpixels = {\n",
    "        datasets.CLASSNAMES[pred_classes[i].item()] : counts[i].item()\n",
    "        for i in topcounts_idx\n",
    "    }\n",
    "\n",
    "    return top_k_classpixels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "This section calculates some metrics through different ways:\n",
    " - Manually comparix pixel values\n",
    " - Metrics classes from MonAI\n",
    " - Metrics based on ConfusionMatrixMetrix from MONAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.stack([ds_train[i][0] for i in range(3)])\n",
    "mask = torch.stack([ds_train[i][1] for i in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model(img.to(device))\n",
    "    pred = pred.to(device='cpu')\n",
    "    pred_amax = torch.argmax(pred, dim=1, keepdim=True).to(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 256, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_amax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'background': 147526, 'cat': 29973, 'bus': 15064, 'sofa': 985}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topclass_dict(pred_amax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required format for MONAI metrics:\n",
    "# float, but 1.0 at whatever we define as predicting a class, 0.0 elsewhere\n",
    "pred_binarized = torch.zeros_like(pred).scatter_(1, pred_amax, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12 is dog\n",
    "pred_amax[2,:,128,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9 is chair\n",
    "pred_amax[2,:,10,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21, 256, 256])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_binarized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class slice through center pixel, should be dog\n",
    "pred_binarized[2,:,128,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class slice through top center pixel, should be chair\n",
    "pred_binarized[2,:,9,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this better be 1\n",
    "pred_binarized.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_onehot = torch.zeros_like(pred).scatter_(1, mask.to(dtype=torch.long), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21, 256, 256])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_onehot[2,:,9,128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[61316,  3884,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,   336,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [51571,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         13965],\n",
       "        [15904,     0,     0,     0,     0,     0,     0,     0,     0, 36763,\n",
       "             0,     0, 12869,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pixels in the mask per class per batch\n",
    "pixelcount_mask = mask_onehot.count_nonzero(dim=(-2,-1))\n",
    "pixelcount_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51413,     0,     0,     0,     0,     0, 14121,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     2,\n",
       "             0],\n",
       "        [61957,     0,     0,     0,     0,     0,   935,    11,  2123,     0,\n",
       "             0,     0,     0,     0,   281,     0,     0,    39,     0,    99,\n",
       "            91],\n",
       "        [34156,     0,     0,     0,     0,     0,     8,     0, 27850,     0,\n",
       "             1,   492,     4,   786,     0,   472,     0,   776,   985,     6,\n",
       "             0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pixels in the prediction per class per batch\n",
    "pixelcount_pred = pred_binarized.count_nonzero(dim=(-2,-1))\n",
    "pixelcount_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[51201,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [48749,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [12777,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pixels BOTH in the mask AND prediction per class per batch\n",
    "pixelcount_intersection = torch.logical_and(mask_onehot, pred_binarized).count_nonzero(dim=(-2,-1))\n",
    "pixelcount_intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[61528,  3884,     0,     0,     0,     0, 14121,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,   336,     0,     0,     0,     2,\n",
       "             0],\n",
       "        [64779,     0,     0,     0,     0,     0,   935,    11,  2123,     0,\n",
       "             0,     0,     0,     0,   281,     0,     0,    39,     0,    99,\n",
       "         14056],\n",
       "        [37283,     0,     0,     0,     0,     0,     8,     0, 27850, 36763,\n",
       "             1,   492, 12871,   786,     0,   472,     0,   776,   985,     6,\n",
       "             0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of pixels EITHER in the mask OR prediction per class per batch\n",
    "pixelcount_union = torch.logical_or(mask_onehot, pred_binarized).count_nonzero(dim=(-2,-1))\n",
    "pixelcount_union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy\n",
    "\n",
    "or Old Pixel-Wise Accuracy\n",
    "\n",
    "Simply the sum of the correctly predicted pixels in this batch divided by the total number of pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 256, 256])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 256, 256])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_amax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5734)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (mask == pred_amax)\n",
    "acc = (acc.sum()/acc.numel())\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5734)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = (mask == pred_amax).count_nonzero() / mask.numel()\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 256, 256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 256])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.size()[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dice Score / F1-Score\n",
    "\n",
    "https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "\n",
    "Sets:\n",
    "\n",
    "`DSC = 2*|A^B| / (|A| + |B|)`\n",
    "\n",
    "\n",
    "Bool only:\n",
    "\n",
    "`DSC = 2*FP / (2*TP + FP + FN)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample-Wise Dice score\n",
    "\n",
    "Only pixels in one prediction will be compared to pixels in the corresponding target mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0839e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [8.5880e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [5.1047e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.1073e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_samplewise = 2 * pixelcount_intersection / (pixelcount_pred + pixelcount_mask)\n",
    "dice_samplewise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mean Dice\n",
    "\n",
    "All pixels of the dataset within one class will be added up and a per-class dice score calculated from that.\n",
    "The overall mean dice is the per-class dice score averaged over the classes.\n",
    "\n",
    "This has the effect that underrepresented classes contribute equally to the overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1593e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.1073e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate pixels over batches\n",
    "\n",
    "dice_batchagg = 2.0 * pixelcount_intersection.sum(dim=0) / (pixelcount_pred + pixelcount_mask).sum(dim=0)\n",
    "dice_batchagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0510)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate avarage over classes. This is our meanDice\n",
    "dice_batchagg.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore prediction of classes that were not in the mask, corresponds to ignore_empty=True\n",
    "# this is for comparing with monai.metrics.DiceMetrics\n",
    "dn = (pixelcount_pred + pixelcount_mask)\n",
    "dn_nonempty = torch.where(pixelcount_mask > 0, dn, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1593e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "        3.1073e-04,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "               nan,        nan, 0.0000e+00])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate pixels over batches\n",
    "\n",
    "dice_batchagg_nonempty = 2.0 * pixelcount_intersection.sum(dim=0) / dn_nonempty.sum(dim=0)\n",
    "dice_batchagg_nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1360)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then average over classes\n",
    "mean_dice_nonempty = dice_batchagg_nonempty.nanmean()\n",
    "mean_dice_nonempty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### monai.metrics.DiceMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = monai.metrics.DiceMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0839e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [8.5880e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00],\n",
       "        [5.1047e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "         3.1073e-04,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = metric(pred_binarized, mask_onehot)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.5922e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.1073e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.aggregate(reduction=\"mean_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3008])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_samplewise_nonempty = torch.where(pixelcount_mask != 0, dice_samplewise, torch.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3008)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_samplewise_nonempty.nanmean(dim=1).nanmean(dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU (Intersection over Union / Jaccard)\n",
    "\n",
    "https://en.wikipedia.org/wiki/Jaccard_index\n",
    "\n",
    "Sets:\n",
    "\n",
    "`DSC = |A^B| / (|A| v |B|)`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample-Wise IoU\n",
    "\n",
    "Only pixels in one prediction will be compared to pixels in the corresponding target mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5539e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IoU per one sample\n",
    "iou_samplewise = pixelcount_intersection / pixelcount_union\n",
    "iou_samplewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5539e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IoU per one sample, calculated from values available in confusion matrix should be same as above\n",
    "iou_samplewise = pixelcount_intersection / (pixelcount_pred + pixelcount_mask - pixelcount_intersection)\n",
    "iou_samplewise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mIoU (mean IoU / mean Jaccard Index)\n",
    "\n",
    "All pixels of the dataset within one class will be added up and a per-class IoU score calculated from that.\n",
    "The overall mean IoU is the per-class IoU score averaged over the classes.\n",
    "\n",
    "This has the effect that underrepresented classes contribute equally to the overall score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8908e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.5539e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate pixels over batches\n",
    "\n",
    "my_iou_batchagg = pixelcount_intersection.sum(dim=0) / (pixelcount_pred + pixelcount_mask - pixelcount_intersection).sum(dim=0)\n",
    "my_iou_batchagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn nans into ones, this corresponds to ignore_empty=False\n",
    "my_iou_batchagg_withempty = my_iou_batchagg.nan_to_num(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2709)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then average over classes\n",
    "my_mean_iou_withempty = my_iou_batchagg_withempty.mean()\n",
    "my_mean_iou_withempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore prediction of classes that were not in the mask, corresponds to ignore_empty=True\n",
    "# TODO: Think hard about whether this is actually a good idea\n",
    "pixelcount_union_nonempty = torch.where(pixelcount_mask > 0, pixelcount_union, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8908e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "        1.5539e-04,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "               nan,        nan, 0.0000e+00])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregate pixels over batches\n",
    "\n",
    "iou_batchagg_nonempty = pixelcount_intersection.sum(dim=0) / pixelcount_union_nonempty.sum(dim=0)\n",
    "iou_batchagg_nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1149)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then average over classes\n",
    "mean_iou_nonempty = iou_batchagg_nonempty.nanmean()\n",
    "mean_iou_nonempty"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### monai.metrics.MeanIoU()\n",
    "\n",
    "This calculates a \"mean\" IoU, but the wrong one: it first calculates the sample IoU, then averages over channels then\n",
    "over batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = monai.metrics.MeanIoU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "         1.5539e-04,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = metric(y_pred=pred_binarized, y=mask_onehot)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2560])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.aggregate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "         1.5539e-04,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nan out classes that were not in the target mask at all\n",
    "# This is equivalent to MONAI metrics ignore_empty=True\n",
    "iou_samplewise_nonempty = torch.where(pixelcount_mask != 0, iou_samplewise, torch.nan)\n",
    "iou_samplewise_nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2560)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MeanIoU from MonAI is equivalent to averaging sample-wise IoU scores\n",
    "iou_samplewise_nonempty.nanmean(dim=1).nanmean(dim=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics based on Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "confm_metrics_types = [\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"accuracy\",\n",
    "    \"f1 score\", # aka Dice Score\n",
    "    \"threat score\" # aka Intersection over Union aka Jaccard Index\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "confm_metric = monai.metrics.ConfusionMatrixMetric(metric_name=confm_metrics_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "confm = confm_metric(y_pred=pred_binarized, y=mask_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 21, 4])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1201e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [4.8749e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.2777e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true positives\n",
    "tp = confm[:,:,0]\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.1200e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.4121e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.0000e+00, 0.0000e+00],\n",
       "        [1.3208e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         9.3500e+02, 1.1000e+01, 2.1230e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 2.8100e+02, 0.0000e+00, 0.0000e+00, 3.9000e+01,\n",
       "         0.0000e+00, 9.9000e+01, 9.1000e+01],\n",
       "        [2.1379e+04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         8.0000e+00, 0.0000e+00, 2.7850e+04, 0.0000e+00, 1.0000e+00, 4.9200e+02,\n",
       "         2.0000e+00, 7.8600e+02, 0.0000e+00, 4.7200e+02, 0.0000e+00, 7.7600e+02,\n",
       "         9.8500e+02, 6.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false positives\n",
    "fp = confm[:,:,1]\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4008., 61652., 65536., 65536., 65536., 65536., 51415., 65536., 65536.,\n",
       "         65536., 65536., 65536., 65536., 65536., 65536., 65200., 65536., 65536.,\n",
       "         65536., 65534., 65536.],\n",
       "        [  757., 65536., 65536., 65536., 65536., 65536., 64601., 65525., 63413.,\n",
       "         65536., 65536., 65536., 65536., 65536., 65255., 65536., 65536., 65497.,\n",
       "         65536., 65437., 51480.],\n",
       "        [28253., 65536., 65536., 65536., 65536., 65536., 65528., 65536., 37686.,\n",
       "         28773., 65535., 65044., 52665., 64750., 65536., 65064., 65536., 64760.,\n",
       "         64551., 65530., 65536.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# true negatives\n",
    "tn = confm[:,:,2]\n",
    "tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10115.,  3884.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,   336.,     0.,     0.,\n",
       "             0.,     0.,     0.],\n",
       "        [ 2822.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0., 13965.],\n",
       "        [ 3127.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "         36763.,     0.,     0., 12867.,     0.,     0.,     0.,     0.,     0.,\n",
       "             0.,     0.,     0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# false negatives\n",
    "fn = confm[:,:,3]\n",
    "fn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9959,    nan,    nan,    nan,    nan,    nan, 0.0000,    nan,    nan,\n",
       "            nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
       "            nan, 0.0000,    nan],\n",
       "        [0.7868,    nan,    nan,    nan,    nan,    nan, 0.0000, 0.0000, 0.0000,\n",
       "            nan,    nan,    nan,    nan,    nan, 0.0000,    nan,    nan, 0.0000,\n",
       "            nan, 0.0000, 0.0000],\n",
       "        [0.3741,    nan,    nan,    nan,    nan,    nan, 0.0000,    nan, 0.0000,\n",
       "            nan, 0.0000, 0.0000, 0.5000, 0.0000,    nan, 0.0000,    nan, 0.0000,\n",
       "         0.0000, 0.0000,    nan]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision (sample-wise)\n",
    "tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7641,    nan,    nan,    nan,    nan,    nan, 0.0000, 0.0000, 0.0000,\n",
       "           nan, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,    nan, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class precision of batch aggregate\n",
    "precision_batchagg = tp.sum(dim=0) / (tp + fp).sum(dim=0)\n",
    "precision_batchagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7641,    nan,    nan,    nan,    nan,    nan, 0.0000, 0.0000, 0.0000,\n",
       "           nan, 0.0000, 0.0000, 0.5000, 0.0000, 0.0000, 0.0000,    nan, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class precision of batch aggregate, calculated through the confusion matrix metric\n",
    "# this is what we want\n",
    "confm_metric.aggregate(reduction=\"sum_batch\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0903)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall precision (batch aggregate precision averaged over non-nan classes)\n",
    "# this is what we want\n",
    "precision_batchagg.nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5734])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduction of confusion matrix values prior to metric calculation\n",
    "# This is NOT what we want.\n",
    "confm_metric.aggregate(reduction=\"mean\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5734)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.sum() / (tp.sum() + fp.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3503e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan,        nan,        nan],\n",
       "        [9.4528e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00],\n",
       "        [8.0338e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "         1.5541e-04,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall (sample-wise)\n",
    "tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.7527e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "        1.5541e-04,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "               nan,        nan, 0.0000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class recall of batch aggregate.\n",
    "# This is what we want\n",
    "tp.sum(dim=0) / (tp + fn).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.7527e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "               nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "        1.5541e-04,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "               nan,        nan, 0.0000e+00])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class recall, calculated through the confusion matrix metric\n",
    "# this is what we want\n",
    "confm_metric.aggregate(reduction=\"sum_batch\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1459)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall recall\n",
    "torch.nanmean(tp.sum(dim=0) / (tp + fn).sum(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5734])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confm_metric.aggregate(reduction=\"mean\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5734)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.sum() / (tp.sum() + fn.sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Accuracy from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8424, 0.9407, 1.0000, 1.0000, 1.0000, 1.0000, 0.7845, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9949, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000],\n",
       "        [0.7554, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9857, 0.9998, 0.9676,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9957, 1.0000, 1.0000, 0.9994,\n",
       "         1.0000, 0.9985, 0.7855],\n",
       "        [0.6261, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.5750,\n",
       "         0.4390, 1.0000, 0.9925, 0.8036, 0.9880, 1.0000, 0.9928, 1.0000, 0.9882,\n",
       "         0.9850, 0.9999, 1.0000]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample-wise accuracy from confusion matrix\n",
    "(tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8424, 0.9407, 1.0000, 1.0000, 1.0000, 1.0000, 0.7845, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9949, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000],\n",
       "        [0.7554, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9857, 0.9998, 0.9676,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9957, 1.0000, 1.0000, 0.9994,\n",
       "         1.0000, 0.9985, 0.7855],\n",
       "        [0.6261, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.5750,\n",
       "         0.4390, 1.0000, 0.9925, 0.8036, 0.9880, 1.0000, 0.9928, 1.0000, 0.9882,\n",
       "         0.9850, 0.9999, 1.0000]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate accuracy\n",
    "confm_metric.aggregate(reduction=\"none\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(112729.)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConfusionMatrixMetric aggregates hits per-class. We can recover the overall hits by summing over only the\n",
    "# true positives and NOT the true negatives, because the true negatives from each class will be contained within\n",
    "# the true positives of the matching class\n",
    "tp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(112729)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask == pred_amax).count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(83879.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# incorrectly identified pixels will count towards the \"false positives\"\n",
    "fp.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(83879)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mask != pred_amax).count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(196608.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of pixels from confusion matrix\n",
    "(tp+fp).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196608"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5734)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall accuracy calculated from per-class TP/FP\n",
    "tp.sum() / (tp+fp).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean Accuracy from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7413, 0.9802, 1.0000, 1.0000, 1.0000, 1.0000, 0.9234, 0.9999, 0.8475,\n",
       "        0.8130, 1.0000, 0.9975, 0.9345, 0.9960, 0.9986, 0.9959, 1.0000, 0.9959,\n",
       "        0.9950, 0.9995, 0.9285])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate accuracy, calculated through the confusion matrix metric\n",
    "(tp + tn).sum(dim=0) / (tp + tn + fp + fn).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9594)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy aka per-class averaged accuracy\n",
    "(tp + tn).sum() / (tp + tn + fp + fn).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7413, 0.9802, 1.0000, 1.0000, 1.0000, 1.0000, 0.9234, 0.9999, 0.8475,\n",
       "        0.8130, 1.0000, 0.9975, 0.9345, 0.9960, 0.9986, 0.9959, 1.0000, 0.9959,\n",
       "        0.9950, 0.9995, 0.9285])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate accuracy\n",
    "confm_metric.aggregate(reduction=\"sum_batch\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9594])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy aka per-class averaged accuracy\n",
    "confm_metric.aggregate(reduction=\"sum\")[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean Dice from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0839e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [8.5880e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [5.1047e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.1073e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample-wise dice from confusion matrix\n",
    "2.0*tp / (2.0 * tp + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0839e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [8.5880e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [5.1047e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.1073e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_samplewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1593e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.1073e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate Dice, calculated through the confusion matrix metric\n",
    "# this is what we want\n",
    "2.0*tp.sum(dim=0) / (2.0 * tp + fn + fp).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.1593e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        3.1073e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate IoU\n",
    "# this is what we want\n",
    "confm_metric.aggregate(reduction=\"sum_batch\")[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0510)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2.0*tp.sum(dim=0) / (2.0 * tp + fn + fp).sum(dim=0)).nanmean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean IoU from confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5539e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample-wise IoU from confusion matrix\n",
    "tp / (tp + fn + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3216e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan,        nan,        nan,        nan,        nan,\n",
       "                nan,        nan,        nan, 0.0000e+00,        nan,        nan,\n",
       "                nan, 0.0000e+00,        nan],\n",
       "        [7.5254e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00,        nan,        nan,        nan,\n",
       "                nan,        nan, 0.0000e+00,        nan,        nan, 0.0000e+00,\n",
       "                nan, 0.0000e+00, 0.0000e+00],\n",
       "        [3.4270e-01,        nan,        nan,        nan,        nan,        nan,\n",
       "         0.0000e+00,        nan, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         1.5539e-04, 0.0000e+00,        nan, 0.0000e+00,        nan, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00,        nan]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to manually calculated sample-wise IoU for comparison\n",
    "iou_samplewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8908e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.5539e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate IoU, calculated through the confusion matrix metric\n",
    "# this is what we want\n",
    "tp.sum(dim=0) / (tp + fn + fp).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8908e-01, 0.0000e+00,        nan,        nan,        nan,        nan,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        1.5539e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,        nan, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# per-class batch aggregate IoU\n",
    "# this is what we want\n",
    "confm_metric.aggregate(reduction=\"sum_batch\")[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0431)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tp.sum(dim=0) / (tp + fn + fp).sum(dim=0)).nanmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4019])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduction of confusion matrix values prior to metric calculation\n",
    "# This is NOT what we want.\n",
    "confm_metric.aggregate(reduction=\"sum\")[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4019)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reduction of confusion matrix values prior to metric calculation\n",
    "# This is NOT what we want.\n",
    "confm_iou_mean = tp.sum() / (tp.sum() + fn.sum() + fp.sum())\n",
    "confm_iou_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics.MultiMetrics class\n",
    "\n",
    "My MultiMetrics class uses all the metrics calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimetrics = metrics.MultiMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "multimetrics.update(pred, mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'OverallAccuracy': 0.5733693440755209,\n",
       " 'MeanPrecision': 0.0902940109372139,\n",
       " 'MeanRecall': 0.14590436220169067,\n",
       " 'MeanAccuracy': 0.9593685865402222,\n",
       " 'MeanDice': 0.051014743745326996,\n",
       " 'MeanIoU': 0.043077364563941956}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimetrics.calculate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89104300547b5a491684fb48aa5fbbf869df96c0a93b8b24f3232becaed215cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
